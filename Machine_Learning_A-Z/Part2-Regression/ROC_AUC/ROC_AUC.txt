"https://github.com/Gurubux/Udemy-ML/blob/master/Machine_Learning_A-Z/Part2-Regression/ROC_AUC/ROC_AUC.ipynb"
------------------------------------------------------------------------------------------
AREA UNDER THE RECEIVER OPERATING CHARACTERISTIC CURVE ( AUC ROC  )
------------------------------------------------------------------------------------------
Classification
---------------------------------------------------------
https://www.youtube.com/watch?v=xugjARegisk&feature=youtu.be



1. Receiver Operating Characteristic Curves Demystified (in Python) 
	https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0
	Good or Bad ROC
	https://raw.githubusercontent.com/Gurubux/Udemy-ML/master/Machine_Learning_A-Z/Part2-Regression/ROC_AUC/ROC_AUC.png

2. Understanding ROC Curves with Python 
	https://stackabuse.com/understanding-roc-curves-with-python/


3. How and When to Use ROC Curves and Precision-Recall Curves for Classification in Python 
	https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/


4. Receiver Operating Characteristic (ROC) 
	https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html


# ROC_AUC.ipynb  - https://github.com/Gurubux/Udemy-ML/blob/master/Machine_Learning_A-Z/Part2-Regression/ROC_AUC/ROC_AUC.ipynb 
from sklearn.metrics import roc_curve  
from sklearn.metrics import roc_auc_score  
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import f1_score
from sklearn.metrics import average_precision_score
from sklearn.metrics import auc


#ROC CURVE
# calculate AUC
auc = roc_auc_score(testy, probs)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(testy, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')

#PRECISION-RECALL CURVE
# calculate precision-recall curve
precision, recall, thresholds = precision_recall_curve(testy, probs)
# calculate F1 score
f1 = f1_score(testy, yhat)
# calculate precision-recall AUC
auc = auc(recall, precision)
# calculate average precision score
ap = average_precision_score(testy, probs)
print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))
# plot no skill
pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')
# plot the precision-recall curve for the model
pyplot.plot(recall, precision, marker='.')

>>>f1=0.836 auc=0.892 ap=0.840

#ROC CURVE PLOT
def plot_roc_curve(fpr, tpr):  
    plt.plot(fpr, tpr, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    plt.show()


--------------------------------------------------------------------------
#https://github.com/Gurubux/Data-Lit/blob/master/2-StatisticsAndProbability/2.1-CreditScoring/Loan_Default_Prediction.ipynb
plotAUC()