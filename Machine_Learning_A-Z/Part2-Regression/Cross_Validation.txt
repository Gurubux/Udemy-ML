Cross-Validation allows us to compare different machine learning methods and get a sense of how well they will work in practice.

Training Set and testing set are divided randomly- To choose the best among each for testing is a overhead, thus Cross-validation uses themm all, one at a time, and summarizes the results at the end.
Example : Consider 4 blocks of data : Total Data : |--1-25%--|--2-25%--|--3-25%--|--4-25%--|
			1. Cross-validation will start by using the 1st three blocks to train the model and Last block to test the model
			2. Keeps track how well the model did, say test data had 5 - Correct and 1 - InCorrect answer
			3. Repeat all combinations and keep track and then which ever ML Algo(SVM, Logistic, DT, RF etc.) gives best result for all test blocks combined that is chosen.
		Since we divided data in 4 blocks this is called as 'FOUR-FOLD CROSS VALIDATION'
		We can consider each sample as a test data, 'LEAVE ONE OUT CROSS VALIDATION'
		TEN-FOLD CROSS VALIDATION is a common practice


https://www.pythonforengineers.com/cross-validation-and-model-selection/

# COde to perform TEN-FOLD CROSS VALIDATION
rf_class = RandomForestClassifier(n_estimators=10)
log_class = LogisticRegression()
svm_class = svm.SVC()

print(cross_val_score(rf_class, data_input, data_output, scoring='accuracy', cv = 10))
# [ 1.          0.93333333  1.          0.93333333  0.93333333  0.93333333 	 0.86666667  1.          1.          1.        ]

print("Random Forests: ")
print(cross_val_score(rf_class, data_input, data_output, scoring='accuracy', cv = 10))
accuracy = cross_val_score(rf_class, data_input, data_output, scoring='accuracy', cv = 10).mean() * 100
print("Accuracy of Random Forests is: " , accuracy)
 
print("\n\nSVM:")
print(cross_val_score(svm_class, data_input, data_output, scoring='accuracy', cv = 10))
accuracy = cross_val_score(svm_class, data_input, data_output, scoring='accuracy', cv = 10).mean() * 100
print("Accuracy of SVM is: " , accuracy)
 
print("\n\nLog:")
print(cross_val_score(log_class, data_input, data_output, scoring='accuracy', cv = 10))
accuracy = cross_val_score(log_class, data_input, data_output, scoring='accuracy', cv = 10).mean() * 100
print("Accuracy of SVM is: " , accuracy)


"""
Random Forests: 
[ 1.          0.93333333  1.          0.93333333  0.93333333  0.93333333
  0.86666667  1.          1.          1.        ]
Accuracy of Random Forests is:  95.3333333333
 
 
SVM:
[ 1.          0.93333333  1.          1.          1.          0.93333333
  0.93333333  1.          1.          1.        ]
Accuracy of SVM is:  98.0
 
 
Log:
[ 1.          1.          1.          0.93333333  0.93333333  0.93333333
  0.8         0.93333333  1.          1.        ]
Accuracy of SVM is:  95.3333333333
"""